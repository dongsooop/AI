{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f30ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ÑÏ≤¥ ÎùºÏù¥Î∏åÎü¨Î¶¨ Î™®ÏïÑÎëêÍ∏∞\n",
    "import pandas as pd\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "import json\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a55502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"#@[^#]+#\", \"\", text)\n",
    "    text = re.sub(r\"[!@#\\$%^&*\\(\\)\\[\\]_+=<>?/|\\\\~`\\\"';:]{2,}\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def filename_to_style(filename):\n",
    "    if \"Í∞úÏù∏Î∞èÍ¥ÄÍ≥Ñ\" in filename or \"Ïó¨Í∞ÄÏÉùÌôú\" in filename:\n",
    "        return \"[Ïä§ÌÉÄÏùº:ÏπúÍ∑ºÌïòÍ≤å]\"\n",
    "    elif \"ÏùºÍ≥ºÏßÅÏóÖ\" in filename or \"ÏãúÏÇ¨ÍµêÏú°\" in filename:\n",
    "        return \"[Ïä§ÌÉÄÏùº:Í≥µÏÜêÌïòÍ≤å]\"\n",
    "    else:\n",
    "        return \"[Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\"\n",
    "\n",
    "def preprocess_dialogues(json_path, style_tag=\"[Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\", save_path=None):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for dialogue in data.get('data', []):\n",
    "        body = dialogue['body']\n",
    "        body.sort(key=lambda x: (x['turnID'], x['utteranceID']))\n",
    "\n",
    "        prev_participant = None\n",
    "        prev_text = \"\"\n",
    "\n",
    "        for utt in body:\n",
    "            pid = utt['participantID']\n",
    "            text = clean_text(utt['utterance'])\n",
    "\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            if prev_participant and pid != prev_participant:\n",
    "                response = f\"{style_tag} {text}\"\n",
    "                pairs.append((prev_text, response))\n",
    "\n",
    "            prev_participant = pid\n",
    "            prev_text = text\n",
    "\n",
    "    if save_path:\n",
    "        df = pd.DataFrame(pairs, columns=[\"input\", \"response\"])\n",
    "        df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å: {save_path} ({len(pairs)}Í∞ú ÏÉòÌîå)\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def preprocess_all_jsons(input_dir, output_csv_path):\n",
    "    all_pairs = []\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_path = os.path.join(root, filename)\n",
    "                style_tag = filename_to_style(filename)\n",
    "                print(f\"üìÅ {filename} ‚Üí Ïä§ÌÉÄÏùº: {style_tag}\")\n",
    "                try:\n",
    "                    pairs = preprocess_dialogues(json_path, style_tag=style_tag)\n",
    "                    all_pairs.extend(pairs)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå ÏóêÎü¨ in {filename}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_pairs, columns=[\"input\", \"response\"])\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"‚úÖ Ï†ÑÏ≤¥ Ï†ÄÏû• ÏôÑÎ£å: {output_csv_path} ({len(all_pairs)}Í∞ú ÏÉòÌîå)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bc3c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ ÏÉÅÍ±∞Îûò(ÏáºÌïë).json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ ÏãùÏùåÎ£å.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ ÎØ∏Ïö©Í≥ºÍ±¥Í∞ï.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ Ïó¨Í∞ÄÏÉùÌôú.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:ÏπúÍ∑ºÌïòÍ≤å]\n",
      "üìÅ ÏãúÏÇ¨ÍµêÏú°.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Í≥µÏÜêÌïòÍ≤å]\n",
      "üìÅ ÏùºÍ≥ºÏßÅÏóÖ.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Í≥µÏÜêÌïòÍ≤å]\n",
      "üìÅ Í∞úÏù∏Î∞èÍ¥ÄÍ≥Ñ.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:ÏπúÍ∑ºÌïòÍ≤å]\n",
      "üìÅ ÌñâÏÇ¨.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ Ï£ºÍ±∞ÏôÄÏÉùÌôú.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "‚úÖ Ï†ÑÏ≤¥ Ï†ÄÏû• ÏôÑÎ£å: ../data/text_dataset/save_path/train_pairs.csv (11322366Í∞ú ÏÉòÌîå)\n",
      "üìÅ ÏÉÅÍ±∞Îûò(ÏáºÌïë).json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ ÏãùÏùåÎ£å.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ ÎØ∏Ïö©Í≥ºÍ±¥Í∞ï.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ Ïó¨Í∞ÄÏÉùÌôú.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:ÏπúÍ∑ºÌïòÍ≤å]\n",
      "üìÅ ÏãúÏÇ¨ÍµêÏú°.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Í≥µÏÜêÌïòÍ≤å]\n",
      "üìÅ ÏùºÍ≥ºÏßÅÏóÖ.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Í≥µÏÜêÌïòÍ≤å]\n",
      "üìÅ Í∞úÏù∏Î∞èÍ¥ÄÍ≥Ñ.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:ÏπúÍ∑ºÌïòÍ≤å]\n",
      "üìÅ ÌñâÏÇ¨.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "üìÅ Ï£ºÍ±∞ÏôÄÏÉùÌôú.json ‚Üí Ïä§ÌÉÄÏùº: [Ïä§ÌÉÄÏùº:Ï§ëÎ¶Ω]\n",
      "‚úÖ Ï†ÑÏ≤¥ Ï†ÄÏû• ÏôÑÎ£å: ../data/text_dataset/save_path/valid_pairs.csv (1415657Í∞ú ÏÉòÌîå)\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../data/text_dataset/·Ñí·Ö°·Ü´·ÑÄ·ÖÆ·Ü®·Ñã·Ö•SNS_train/[ÎùºÎ≤®]ÌïúÍµ≠Ïñ¥SNS_train\"\n",
    "valid_dir = \"../data/text_dataset/·Ñí·Ö°·Ü´·ÑÄ·ÖÆ·Ü®·Ñã·Ö•SNS_valid/[ÎùºÎ≤®]ÌïúÍµ≠Ïñ¥SNS_valid\"\n",
    "\n",
    "train_output = \"../data/text_dataset/save_path/train_pairs.csv\"\n",
    "valid_output = \"../data/text_dataset/save_path/valid_pairs.csv\"\n",
    "\n",
    "preprocess_all_jsons(train_dir, train_output)\n",
    "preprocess_all_jsons(valid_dir, valid_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2aba58",
   "metadata": {},
   "source": [
    "### train_pairs.csv , valid_pairs.csv -> train.txtÎ°ú Î≥ëÌï©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b4bfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_to_text(train_csv, valid_csv, output_txt):\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    df_valid = pd.read_csv(valid_csv)\n",
    "    \n",
    "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "        for df in [df_train, df_valid]:\n",
    "            for i in range(len(df)):\n",
    "                input_text = str(df.loc[i, \"input\"]).strip()\n",
    "                response_text = str(df.loc[i, \"response\"]).strip()\n",
    "                if input_text and response_text:\n",
    "                    f.write(input_text + '\\n')\n",
    "                    f.write(response_text + '\\n')\n",
    "                    \n",
    "merge_csv_to_text(\n",
    "    \"../data/text_dataset/save_path/train_pairs.csv\",\n",
    "    \"../data/text_dataset/save_path/valid_pairs.csv\",\n",
    "    \"../data/text_dataset/text_for_txt/train.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae4ba312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sentencepiece(input_file, model_dir=\"../model/llm_model\", model_name=\"chatbot_spm_ver2\", vocab_size=16000):\n",
    "\n",
    "    model_prefix = os.path.join(model_dir, model_name)\n",
    "\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input={input_file} --model_prefix={model_prefix} --vocab_size={vocab_size} \"\n",
    "        \"--model_type=bpe --character_coverage=1.0 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3\"\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {model_prefix}.model\")\n",
    "    print(f\"‚úÖ Îã®Ïñ¥ ÏÇ¨Ï†Ñ Ï†ÄÏû• ÏôÑÎ£å: {model_prefix}.vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d322779",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sentencepiece' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ïã§Ìñâ ÏòàÏãú\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_sentencepiece(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/text_dataset/text_for_txt/train.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/llm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_spm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sentencepiece' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=../data/text_dataset/text_for_txt/train.txt --model_prefix=../model/llm_model/chatbot_ver2_spm --vocab_size=16000 --model_type=bpe --character_coverage=1.0 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/text_dataset/text_for_txt/train.txt\n",
      "  input_format: \n",
      "  model_prefix: ../model/llm_model/chatbot_ver2_spm\n",
      "  model_type: BPE\n",
      "  vocab_size: 16000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: ../data/text_dataset/text_for_txt/train.txt\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(378) LOG(WARNING) Found too long line (5081 > 4192).\n",
      "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 4000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 5000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 6000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 7000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 8000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 9000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 10000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 11000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 12000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 13000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 14000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 15000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 16000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 17000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 18000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 19000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 20000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 21000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 22000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 23000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 24000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 25000000 lines\n",
      "trainer_interface.cc(122) LOG(WARNING) Too many sentences are loaded! (25476018), which may slow down training.\n",
      "trainer_interface.cc(124) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(127) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 25476018 sentences\n",
      "trainer_interface.cc(414) LOG(INFO) Skipped 28 too long sentences.\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=406042201\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 100% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=8962\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 25476016 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 25476016\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 9429972\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20347804 min_freq=286\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1088175 size=20 all=732430 active=61624 piece=‚ñÅÏò§\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=430197 size=40 all=755215 active=84409 piece=‚ñÅÏûò\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=337326 size=60 all=771631 active=100825 piece=‚ñÅ1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=258824 size=80 all=788599 active=117793 piece=‚ñÅÏßë\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=222474 size=100 all=805146 active=134340 piece=‚ñÅÏóÑ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=222319 min_freq=267\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=189514 size=120 all=825452 active=60189 piece=‚ñÅÎπÑ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158703 size=140 all=840704 active=75441 piece=‚ñÅÎèÑ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=140443 size=160 all=856926 active=91663 piece=Ïù¥Îùº\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125457 size=180 all=871768 active=106505 piece=Îã§Í∞Ä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113619 size=200 all=886447 active=121184 piece=·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=113377 min_freq=255\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=105471 size=220 all=901837 active=57674 piece=‚ñÅÌîº\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95654 size=240 all=914870 active=70707 piece=‚ñÅ5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90531 size=260 all=927091 active=82928 piece=‚ñÅÍ±∞Í∏∞\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83464 size=280 all=943113 active=98950 piece=‚ñÅÎÜÄ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77497 size=300 all=957214 active=113051 piece=‚ñÅÏãúÍ∞Ñ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77183 min_freq=240\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72971 size=320 all=968905 active=59106 piece=‚ñÅÎÇ†\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69786 size=340 all=982008 active=72209 piece=Î†áÍ≤å\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67086 size=360 all=994713 active=84914 piece=ÎäîÍ±¥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62581 size=380 all=1005155 active=95356 piece=‚ñÅÏã§\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60137 size=400 all=1019657 active=109858 piece=Í≤†ÎÑ§\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=60111 min_freq=228\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56647 size=420 all=1033578 active=64203 piece=‚ñÅÏóÜÏñ¥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54085 size=440 all=1045041 active=75666 piece=‚ñÅÎ≤å\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52287 size=460 all=1055182 active=85807 piece=‚ñÅÌûà\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50424 size=480 all=1063497 active=94122 piece=‚ñÅÏõêÎûò\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48736 size=500 all=1071498 active=102123 piece=‚ñÅÍ∞ôÏïÑ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48627 min_freq=219\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46377 size=520 all=1081032 active=62946 piece=‚ñÅÏ§Ä\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44320 size=540 all=1090862 active=72776 piece=‚ñÅÏó≠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42771 size=560 all=1099600 active=81514 piece=‚ñÅÏïåÏïÑ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41494 size=580 all=1112354 active=94268 piece=Í≤ÉÍ∞ô\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39715 size=600 all=1124442 active=106356 piece=‚ñÅÏïû\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=39674 min_freq=210\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38301 size=620 all=1134871 active=66387 piece=‚ñÅÎèº\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36468 size=640 all=1144480 active=75996 piece=‚ñÅÎ≠êÏïº\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35305 size=660 all=1154985 active=86501 piece=‚ñÅÍ≥†ÏÉù\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34673 size=680 all=1165444 active=96960 piece=ÏóêÎäî\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33273 size=700 all=1176189 active=107705 piece=‚ñÅÌîºÍ≥§\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=33252 min_freq=203\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32263 size=720 all=1190147 active=72543 piece=‚ñÅÌèâ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31104 size=740 all=1198752 active=81148 piece=‚ñÅÎàÑÍµ¨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29999 size=760 all=1207498 active=89894 piece=‚ñÅÌùë\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29278 size=780 all=1218268 active=100664 piece=‚ñÅÎñ®\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28569 size=800 all=1229532 active=111928 piece=‚ñÅÌïôÍµê\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28534 min_freq=193\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27929 size=820 all=1241573 active=73040 piece=‚ñÅÌòπÏãú\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27293 size=840 all=1253989 active=85456 piece=‚ñÅ·ÑÖ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26578 size=860 all=1264194 active=95661 piece=‚ñÅÍµ≠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25643 size=880 all=1275678 active=107145 piece=‚ñÅÏ†à\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24978 size=900 all=1289937 active=121404 piece=‚ñÅÌôîÏû•\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24968 min_freq=184\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24206 size=920 all=1299805 active=74099 piece=000\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23539 size=940 all=1310903 active=85197 piece=‚ñÅÏù¥Î¶Ñ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22849 size=960 all=1317066 active=91360 piece=Í±∞ÎÇò\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22229 size=980 all=1327679 active=101973 piece=‚ñÅÌôò\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21665 size=1000 all=1338206 active=112500 piece=Ïù¥ÌåÖ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21641 min_freq=177\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21191 size=1020 all=1348553 active=76929 piece=‚ñÅÌïúÍµ≠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20765 size=1040 all=1358406 active=86782 piece=‚ñÅÏïÑÎãàÍ≥†\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20432 size=1060 all=1368499 active=96875 piece=‚ñÅÏ°∞Ïã¨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19931 size=1080 all=1378568 active=106944 piece=‚ñÅÏ†ÄÍ∏∞\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19463 size=1100 all=1389684 active=118060 piece=‚ñÅÏù¥Ìï¥\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19429 min_freq=170\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19019 size=1120 all=1398735 active=78320 piece=Ïù¥ÎùºÎèÑ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18523 size=1140 all=1409648 active=89233 piece=‚ñÅÌôÄ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18285 size=1160 all=1416800 active=96385 piece=‚ñÅÏù¥Îäî\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17870 size=1180 all=1424782 active=104367 piece=Ïñ∏Îãà\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17445 size=1200 all=1435248 active=114833 piece=ÎïåÎ¨∏Ïóê\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17422 min_freq=163\n",
      "bpe_model_trainer.cc(268) L"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ïã§Ìñâ ÏòàÏãú\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_sentencepiece(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/text_dataset/text_for_txt/train.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/llm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_ver2_spm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m, in \u001b[0;36mtrain_sentencepiece\u001b[0;34m(input_file, model_dir, model_name, vocab_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_sentencepiece\u001b[39m(input_file, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/llm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_spm_ver2\u001b[39m\u001b[38;5;124m\"\u001b[39m, vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, model_name)\n\u001b[0;32m----> 5\u001b[0m     spm\u001b[38;5;241m.\u001b[39mSentencePieceTrainer\u001b[38;5;241m.\u001b[39mTrain(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--input=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --model_prefix=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --vocab_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model_type=bpe --character_coverage=1.0 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Îã®Ïñ¥ ÏÇ¨Ï†Ñ Ï†ÄÏû• ÏôÑÎ£å: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logstream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _LogStream(ostream\u001b[38;5;241m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[38;5;241m.\u001b[39m_Train(arg\u001b[38;5;241m=\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:945\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(arg) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 945\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SentencePieceTrainer\u001b[38;5;241m.\u001b[39m_TrainFromString(arg)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(value):\n\u001b[1;32m    948\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Encode value to CSV..\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:923\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromString\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_TrainFromString\u001b[39m(arg):\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sentencepiece\u001b[38;5;241m.\u001b[39mSentencePieceTrainer__TrainFromString(arg)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ïã§Ìñâ ÏòàÏãú\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_sentencepiece(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/text_dataset/text_for_txt/train.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/llm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_ver2_spm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m, in \u001b[0;36mtrain_sentencepiece\u001b[0;34m(input_file, model_dir, model_name, vocab_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_sentencepiece\u001b[39m(input_file, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/llm_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_spm_ver2\u001b[39m\u001b[38;5;124m\"\u001b[39m, vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model_prefix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, model_name)\n\u001b[0;32m----> 5\u001b[0m     spm\u001b[38;5;241m.\u001b[39mSentencePieceTrainer\u001b[38;5;241m.\u001b[39mTrain(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--input=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --model_prefix=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --vocab_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model_type=bpe --character_coverage=1.0 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Îã®Ïñ¥ ÏÇ¨Ï†Ñ Ï†ÄÏû• ÏôÑÎ£å: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mTrain\u001b[39m(arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logstream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m _LogStream(ostream\u001b[38;5;241m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[38;5;241m.\u001b[39m_Train(arg\u001b[38;5;241m=\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:945\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(arg) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 945\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SentencePieceTrainer\u001b[38;5;241m.\u001b[39m_TrainFromString(arg)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(value):\n\u001b[1;32m    948\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Encode value to CSV..\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/sentencepiece/__init__.py:923\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromString\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_TrainFromString\u001b[39m(arg):\n\u001b[0;32m--> 923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _sentencepiece\u001b[38;5;241m.\u001b[39mSentencePieceTrainer__TrainFromString(arg)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ïã§Ìñâ ÏòàÏãú\n",
    "train_sentencepiece(\"../data/text_dataset/text_for_txt/train.txt\", model_dir=\"../model/llm_model\", model_name=\"chatbot_ver2_spm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e3b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(model_path)\n",
    "        \n",
    "        self.pad_id = self.sp.pad_id()\n",
    "        self.unk_id = self.sp.unk_id()\n",
    "        self.bos_id = self.sp.bos_id()\n",
    "        self.eos_id = self.sp.eos_id()\n",
    "    \n",
    "    def encode(self, text: str, add_bos=True, add_eos=True) -> list:\n",
    "        tokens = self.sp.encode(text, out_type=int)\n",
    "        if add_bos:\n",
    "            tokens = [self.bos_id] + tokens\n",
    "        if add_eos:\n",
    "            tokens = tokens + [self.eos_id]\n",
    "        return tokens\n",
    "    \n",
    "    def decode(self, ids: list) -> str:\n",
    "        ids = [i for i in ids if i not in [self.bos_id, self.eos_id, self.pad_id]]\n",
    "        return self.sp.decode(ids)\n",
    "    \n",
    "    def vacab_size(self):\n",
    "        return self.sp.get_piece_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb0426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÏõêÎ¨∏: Ïò§Îäò ÎÇ†Ïî® Ï¢ãÏïÑ?\n",
      "üß† Ïù∏ÏΩîÎî©: [2, 57, 1602, 200, 8898, 3]\n",
      "üîÅ ÎîîÏΩîÎî©: Ïò§Îäò ÎÇ†Ïî® Ï¢ãÏïÑ?\n"
     ]
    }
   ],
   "source": [
    "# ÌÖåÏä§Ìä∏\n",
    "tokenizer = Tokenizer(\"../model/llm_model/chatbot_ver2_spm.model\")\n",
    "\n",
    "text = \"Ïò§Îäò ÎÇ†Ïî® Ï¢ãÏïÑ?\"\n",
    "encoded = tokenizer.encode(text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(\"ÏõêÎ¨∏:\", text)\n",
    "print(\"Ïù∏ÏΩîÎî©:\", encoded)\n",
    "print(\"ÎîîÏΩîÎî©:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e077bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout, bidirectional=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embeded)\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        if hidden.dim() == 2:\n",
    "            hidden = hidden.unsqueeze(1)\n",
    "\n",
    "        # batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        hidden = hidden.repeat(1, seq_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        attn_weight = F.softmax(attention, dim=1)\n",
    "        context = torch.bmm(attn_weight.unsqueeze(1), encoder_outputs)\n",
    "        return context, attn_weight\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=2, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size + hidden_size, hidden_size,\n",
    "                            num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs):\n",
    "        if input_token.dim() == 1:\n",
    "            input_token = input_token.unsqueeze(1)\n",
    "\n",
    "        embedded = self.embedding(input_token)\n",
    "        context, attn_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        lstm_input = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        concat = torch.cat((outputs, context), dim=2)\n",
    "        logits = self.fc_out(concat).squeeze(1)\n",
    "\n",
    "        return logits, hidden, cell, attn_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        vocab_size = self.decoder.embedding.num_embeddings\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "        input_token = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c75543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_len=64):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.inputs = df[\"input\"].astype(str).tolist()\n",
    "        self.responses = df[\"response\"].astype(str).tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src = self.tokenizer.encode(self.inputs[idx])\n",
    "        trg = self.tokenizer.encode(self.responses[idx])\n",
    "\n",
    "        # pad\n",
    "        if len(src) < self.max_len:\n",
    "            src += [self.tokenizer.pad_id] * (self.max_len - len(src))\n",
    "        else:\n",
    "            src = src[:self.max_len]\n",
    "        \n",
    "        if len(trg) < self.max_len:\n",
    "            trg += [self.tokenizer.pad_id] * (self.max_len - len(trg))\n",
    "        else:\n",
    "            trg = trg[:self.max_len]\n",
    "        \n",
    "        return torch.tensor(src), torch.tensor(trg)\n",
    "\n",
    "num_workers = 0\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎçî\n",
    "train_dataset = ChatDataset(\"../data/text_dataset/save_path/train_pairs.csv\", tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=num_workers, pin_memory=False)\n",
    "valid_dataset = ChatDataset(\"../data/text_dataset/save_path/valid_pairs.csv\", tokenizer)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbee78d",
   "metadata": {},
   "source": [
    "### LSTM + Attention Ï±óÎ¥á ÌïôÏäµ\n",
    "1. ÏûÖÎ†•\n",
    " + model : Seq2Seq Î™®Îç∏(Encoder + Attention + Decoder)\n",
    " + dataloader : ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î°úÎçî\n",
    " + tokenizer : Ìå®Îî© ID ÌôïÏù∏Ïö©\n",
    " + num_epochs : ÌïôÏäµ epoch Ïàò\n",
    " + lr : ÌïôÏäµÎ•†\n",
    "2. ÎèôÏûë\n",
    " + Î™®Îç∏ foward\n",
    " + output, target -> reshape\n",
    " + CrossEntropyLoss Í≥ÑÏÇ∞\n",
    " + Ïó≠Ï†ÑÌåå + optimizer ÏóÖÎç∞Ïù¥Ìä∏\n",
    " + tqdm ÏßÑÌñâ ÌëúÏãú Î∞è ÌèâÍ∑† loss Ï∂úÎ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c316630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, tokenizer, num_epochs=5, lr=1e-3, device=None, checkpoint_path=None):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    # gpu Í∏∞Î∞ò\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # PAD ÌÜ†ÌÅ∞ Î¨¥Ïãú\n",
    "    pad_id = tokenizer.pad_id\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_id)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    start_epoch = 0\n",
    "    if checkpoint_path is not None:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        for src, trg in progress_bar:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(src, trg)\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"\\n[Epoch {epoch+1}] ÌèâÍ∑† Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # checkpoint Ï†ÄÏû•\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, f\"checkpoint_epoch{epoch}.pt\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1e4e6",
   "metadata": {},
   "source": [
    "### Î™®Îç∏ Ï†ÄÏû• Î∞è ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14956fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path='../model/llm_model/chatbot_model_v2.pt'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {path}\")\n",
    "\n",
    "def load_model(model, path='../model/llm_model/chatbot_model_v2.pt'):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5cfe9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "@torch.no_grad()\n",
    "def evalute_model(model, dataloader, tokenizer,\n",
    "                    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")):\n",
    "    # device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    for i, (src, trg) in enumerate(dataloader):\n",
    "        if i >= 5: break\n",
    "\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        # infernce Î™®Îìú\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "        pred = output.argmax(dim=-1)\n",
    "\n",
    "        print(\"üü¢ Input :\", tokenizer.decode(src[0].tolist()))\n",
    "        print(\"‚úÖ Target :\", tokenizer.decode(trg[0].tolist()))\n",
    "        print(\"ü§ñ Output :\", tokenizer.decode(pred[0].tolist()))\n",
    "        print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64dc7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reply(model, tokenizer, input_text, max_len=64, \n",
    "                device=torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # ÏûÖÎ†• Ïù∏ÏΩîÎî©\n",
    "    input_ids = tokenizer.encode(input_text)\n",
    "    input_ids = input_ids + [tokenizer.pad_id] * (max_len - len(input_ids))\n",
    "    src = torch.tensor(input_ids).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "\n",
    "    input_token = torch.tensor([tokenizer.bos_id], device=device)  # ÏãúÏûë ÌÜ†ÌÅ∞\n",
    "\n",
    "    generated_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Ïù∏ÏΩîÎçî Ï∂úÎ†•\n",
    "        encoder_outputs, (hidden, cell) = model.encoder(src)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            # üî• encoder_outputs Ï†ÑÎã¨\n",
    "            output, hidden, cell, _ = model.decoder(input_token.view(1, 1), hidden, cell, encoder_outputs)\n",
    "\n",
    "            if t < 5:\n",
    "                output[0][tokenizer.eos_id] = -float('inf')\n",
    "\n",
    "            next_token = output.argmax(1)\n",
    "            \n",
    "            if next_token.item() == tokenizer.eos_id:\n",
    "                break\n",
    "\n",
    "            generated_ids.append(next_token.item())\n",
    "            input_token = next_token\n",
    "\n",
    "    decoded = tokenizer.decode(generated_ids)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b51e6",
   "metadata": {},
   "source": [
    "### ÌÖåÏä§Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0ad873bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat(model, tokenizer, device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")):\n",
    "    # device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"ü§ñ Ï±óÎ¥á ÌÖåÏä§Ìä∏ ÏãúÏûë. Ï¢ÖÎ£åÌïòÎ†§Î©¥ exit ÏûÖÎ†•.\")\n",
    "\n",
    "    while(True):\n",
    "        query = input(\"üë§ ÏÇ¨Ïö©Ïûê: \")\n",
    "        print(\"üë§ ÏÇ¨Ïö©Ïûê: \", query)\n",
    "        if query.strip().lower() in ['exit', 'quit', 'Ï¢ÖÎ£å']:\n",
    "            print(\"üî¥ ÌÖåÏä§Ìä∏ Ï¢ÖÎ£å.\")\n",
    "            break\n",
    "        response = generate_reply(model, tokenizer, query, device=device)\n",
    "        print(\"ü§ñ Ï±óÎ¥á: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec93e35",
   "metadata": {},
   "source": [
    "### Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e178c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(train_loader, valid_loader, tokenizer, model, num_epochs=5):\n",
    "    trained_model = train_model(model, train_loader, tokenizer, num_epochs=num_epochs)\n",
    "\n",
    "    save_model(trained_model, \"model/llm_model/chatbot_model_v2.pt\")\n",
    "\n",
    "    evalute_model(trained_model, valid_loader, tokenizer)\n",
    "\n",
    "    interactive_chat(trained_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc210817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(valid_loader, tokenizer, model):\n",
    "    \n",
    "    test_model = load_model(model)\n",
    "\n",
    "    evalute_model(test_model, valid_loader, tokenizer)\n",
    "\n",
    "    interactive_chat(test_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c66d5",
   "metadata": {},
   "source": [
    "### ÌïôÏäµ ÏãúÏûë Î∞è Î™®Îç∏ Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ffc2914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Input : Î≥¥Í≥†Ïã∂ÎçîÎû¥.. Ïò§ÎùºÍ≥†Îäî Î™ªÌïòÍ≤†Í≥†\n",
      "‚úÖ Target : ÏïÑÏù¥Í≥†..Îã¥Ï£ºÏóê Í∞ÄÏïºÍ≤†ÎÑ§\n",
      "ü§ñ Output : ÎÇòÎèÑ\n",
      "------------------------------------------------------------\n",
      "üü¢ Input : Íº≠ÏÇ¨Î¥êÏïºÏßÄ\n",
      "‚úÖ Target : ·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè ÎÇòÎëê ÏãúÎåÅÍ∞ÄÎäîÎç∞ÎèÑ ·Ñè·ÑèÏ¢ãÎã§·Ñè·Ñè·ÑÄ·ÑÄ\n",
      "ü§ñ Output : Ïùë\n",
      "------------------------------------------------------------\n",
      "üü¢ Input : Ïòπ..Ïôú Î°§Ïù¥ ÏïàÎèº?\n",
      "‚úÖ Target : ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Ïò§Î•òÏù∏ÎìØ\n",
      "ü§ñ Output : ÎÑ¥..\n",
      "------------------------------------------------------------\n",
      "üü¢ Input : Î∂ÑÏúÑÍ∏∞ Í≥ÑÏÜç ÏÇ¥Ìé¥Î¥ê\n",
      "‚úÖ Target : Í∏ÄÍ≥† Ìò∏Ïπ≠ÎèÑ Ïù¥ÎûÄÎßêÏïº\n",
      "ü§ñ Output : ·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè\n",
      "------------------------------------------------------------\n",
      "üü¢ Input : Í∑∏Î•¥Í≤å·ÖÆ·ÖÆ ÌïúÏãúÍ∞ÑÎèôÏïà ÏïïÎ∞ïÎ©¥Ï†ëÏù¥ÎùºÎãà·ÖÆ·ÖÆ\n",
      "‚úÖ Target : ·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·Ñè·ÑèÍº¨Í∏∞ Î®πÏñ¥ÏïºÍ≤üÏóÖ\n",
      "ü§ñ Output : ·Ö≤·Ö≤\n",
      "------------------------------------------------------------\n",
      "ü§ñ Ï±óÎ¥á ÌÖåÏä§Ìä∏ ÏãúÏûë. Ï¢ÖÎ£åÌïòÎ†§Î©¥ exit ÏûÖÎ†•.\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  ÏïàÎÖï?\n",
      "ü§ñ Ï±óÎ¥á:  Ïùë#·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  ÎÑàÎäî ÎàÑÍµ¨Ïïº?\n",
      "ü§ñ Ï±óÎ¥á:  ÎÇò#Îäî ÎÇò?\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  Ïö∞Ïùë ÎÑà ÎßêÏïº\n",
      "ü§ñ Ï±óÎ¥á:  ÎÇò?·Ñè·Ñè·Ñè ÎÇò ÏßÄÍ∏à\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  „Öá\n",
      "ü§ñ Ï±óÎ¥á:  Í∑ºÎç∞#Ïù¥·Öµ·Ñã\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  ÎßûÏïÑ\n",
      "ü§ñ Ï±óÎ¥á:  Í∑ºÎç∞#ÎèÑ ÏïàÏ±ôÍ≤º\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  Î≠ê?\n",
      "ü§ñ Ï±óÎ¥á:  ÎÇò#·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè‚´¨·Ñè\n",
      "üë§ ÏÇ¨Ïö©Ïûê:  exit\n",
      "üî¥ ÌÖåÏä§Ìä∏ Ï¢ÖÎ£å.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = tokenizer.vacab_size()\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size)\n",
    "model = Seq2Seq(encoder, decoder, device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "# gpu Í∏∞Î∞ò\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏\n",
    "# full_pipeline(train_loader, valid_loader, tokenizer, model, num_epochs=5)\n",
    "\n",
    "# ÌÖåÏä§Ìä∏Îßå\n",
    "test_pipeline(valid_loader, tokenizer, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
