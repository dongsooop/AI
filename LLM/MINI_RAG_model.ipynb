{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72895453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19a2f046ee54b7998b1c68589f44607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl_study/lib/python3.11/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, hashlib, numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from difflib import SequenceMatcher\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "with open(\"../data/school_info/old_data/dmu_documents_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_json = pd.DataFrame(data)\n",
    "df_json = df_json.dropna(subset=[\"content\"])\n",
    "df_json[\"title\"] = df_json[\"title\"].fillna(\"\")\n",
    "df_json[\"url\"] = df_json[\"url\"].fillna(\"\")\n",
    "df_json[\"source\"] = \"main\"\n",
    "\n",
    "dept_dir = \"../data/dept\"\n",
    "dept_files = [f for f in os.listdir(dept_dir) if f.endswith(\"_notices.csv\")]\n",
    "\n",
    "df_list = []\n",
    "for file in dept_files:\n",
    "    file_path = os.path.join(dept_dir, file)\n",
    "    try:\n",
    "        df_dept = pd.read_csv(file_path)\n",
    "        df_dept[\"title\"] = df_dept[\"제목\"].fillna(\"\")\n",
    "        df_dept[\"url\"] = df_dept[\"링크\"].fillna(\"\")\n",
    "        df_dept[\"content\"] = (\n",
    "            \"부서: \" + df_dept[\"부서\"].fillna(\"없음\") + \"\\n\"\n",
    "            + \"작성자: \" + df_dept[\"작성자\"].fillna(\"없음\") + \"\\n\"\n",
    "            + \"작성일: \" + df_dept[\"작성일\"].astype(str).fillna(\"없음\")\n",
    "        )\n",
    "        df_dept[\"source\"] = file.replace(\"_notices.csv\", \"\")\n",
    "        df_list.append(df_dept[[\"title\", \"content\", \"url\", \"source\"]])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 파일 오류: {file_path} - {e}\")\n",
    "\n",
    "df_csv = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame(columns=[\"title\", \"content\", \"url\", \"source\"])\n",
    "df = pd.concat([df_json[[\"title\",\"content\",\"url\",\"source\"]], df_csv], ignore_index=True)\n",
    "df = df.dropna(subset=[\"title\", \"content\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def normalize_text(s): \n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "\n",
    "df[\"title\"]   = df[\"title\"].apply(normalize_text)\n",
    "df[\"content\"] = df[\"content\"].apply(normalize_text)\n",
    "df[\"fulltext\"] = (df[\"title\"] + \" \" + df[\"content\"]).apply(normalize_text)\n",
    "df[\"content_hash\"] = df[\"fulltext\"].apply(lambda x: hashlib.sha1(x.encode(\"utf-8\")).hexdigest())\n",
    "df = df.drop_duplicates(subset=[\"url\"]).drop_duplicates(subset=[\"content_hash\"]).reset_index(drop=True)\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "KST_NOW = datetime.now(KST)\n",
    "df[\"notice_flag\"] = (df[\"source\"] != \"main\").astype(int)\n",
    "\n",
    "\n",
    "def try_parse_date(x):\n",
    "    x = str(x)\n",
    "    fmts = (\"%Y-%m-%d\", \"%Y.%m.%d\", \"%Y/%m/%d\", \"%Y%m%d\")\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(x[:10], fmt).replace(tzinfo=KST)\n",
    "        except:\n",
    "            pass\n",
    "    m = re.search(r\"(\\d{4})\\s*년\\s*(\\d{1,2})\\s*월\\s*(\\d{1,2})\\s*일\", x)\n",
    "    if m:\n",
    "        y, mo, d = map(int, m.groups())\n",
    "        return datetime(y, mo, d, tzinfo=KST)\n",
    "    return None\n",
    "\n",
    "\n",
    "date_patterns = [\n",
    "    re.compile(r\"(?:작성일|등록일|게시일)\\s*[:\\-]?\\s*(\\d{4}[./-]\\d{1,2}[./-]\\d{1,2})\"),\n",
    "    re.compile(r\"(?:작성일|등록일|게시일)\\s*[:\\-]?\\s*(\\d{4}\\s*년\\s*\\d{1,2}\\s*월\\s*\\d{1,2}\\s*일)\")\n",
    "]\n",
    "\n",
    "\n",
    "def extract_date_from_content(txt):\n",
    "    if not isinstance(txt, str):\n",
    "        return None\n",
    "    for pat in date_patterns:\n",
    "        m = pat.search(txt)\n",
    "        if m:\n",
    "            return try_parse_date(m.group(1))\n",
    "    return None\n",
    "\n",
    "df[\"updated_at\"] = df.apply(\n",
    "    lambda r: extract_date_from_content(r[\"content\"]) if r[\"notice_flag\"]==1 else None, axis=1\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    import kss\n",
    "    def sent_split(text):\n",
    "        text = str(text).strip()\n",
    "        return [s for s in kss.split_sentences(text) if s.strip()]\n",
    "except Exception:\n",
    "    SENT_PAT = re.compile(r'.+?(?:다\\.|요\\.|[.!?])(?=\\s+|$)')\n",
    "    def sent_split(text):\n",
    "        text = ' '.join(str(text).split())\n",
    "        if not text:\n",
    "            return []\n",
    "        sents = SENT_PAT.findall(text)\n",
    "        return sents if sents else [text]\n",
    "\n",
    "\n",
    "def chunk_text(text, max_tokens=400, overlap=0.15):\n",
    "    sents = [s for s in sent_split(text) if s.strip()]\n",
    "    if not sents:\n",
    "        return []\n",
    "    chunks, cur, tok = [], [], 0\n",
    "    ovl = max(int(max_tokens * overlap), 0)\n",
    "    for s in sents:\n",
    "        t = len(s.split())\n",
    "        if t >= max_tokens and not cur:\n",
    "            chunks.append(s.strip()); continue\n",
    "        if tok + t <= max_tokens:\n",
    "            cur.append(s); tok += t\n",
    "        else:\n",
    "            if cur:\n",
    "                blob = \" \".join(cur).strip()\n",
    "                chunks.append(blob)\n",
    "                if ovl > 0:\n",
    "                    tail_tokens = blob.split()[-ovl:]\n",
    "                    tail = \" \".join(tail_tokens)\n",
    "                    cur = [tail, s]\n",
    "                    tok = len(tail_tokens) + t\n",
    "                else:\n",
    "                    cur = [s]; tok = t\n",
    "            else:\n",
    "                chunks.append(s.strip()); cur, tok = [], 0\n",
    "    if cur:\n",
    "        chunks.append(\" \".join(cur).strip())\n",
    "    return chunks\n",
    "\n",
    "rows = []\n",
    "for i, r in df.iterrows():\n",
    "    parts = chunk_text(r[\"fulltext\"], max_tokens=400, overlap=0.15)\n",
    "    for j, ch in enumerate(parts):\n",
    "        rows.append({\n",
    "            \"doc_id\": i,\n",
    "            \"chunk_id\": f\"{i}-{j}\",\n",
    "            \"title\": r[\"title\"],\n",
    "            \"url\": r[\"url\"],\n",
    "            \"source\": r[\"source\"],\n",
    "            \"notice_flag\": r[\"notice_flag\"],\n",
    "            \"updated_at\": r[\"updated_at\"],\n",
    "            \"text\": ch\n",
    "        })\n",
    "\n",
    "chunk_df = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    from konlpy.tag import Okt\n",
    "    okt = Okt()\n",
    "    def tokenize_kor(s):\n",
    "        return [w for w, pos in okt.pos(s, norm=True, stem=True) \n",
    "                if pos not in (\"Josa\",\"Punctuation\",\"Foreign\")]\n",
    "except Exception:\n",
    "    def tokenize_kor(s):\n",
    "        return re.findall(r\"[가-힣A-Za-z0-9]+\", s)\n",
    "\n",
    "\n",
    "tokenized_corpus = [tokenize_kor(t) for t in chunk_df[\"text\"].tolist()]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-base\")\n",
    "\n",
    "\n",
    "def embed_passages(texts):\n",
    "    return model.encode([f\"passage: {t}\" for t in texts], \n",
    "                        normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=256)\n",
    "def embed_query(q: str):\n",
    "    return model.encode([f\"query: {q}\"], normalize_embeddings=True)[0].astype(np.float32)\n",
    "\n",
    "embeddings = embed_passages(chunk_df[\"text\"].tolist()).astype(np.float32)\n",
    "\n",
    "\n",
    "PHONE_RE = re.compile(r\"\\b0\\d{1,2}[-\\s]?\\d{3,4}[-\\s]?\\d{4}\\b\")\n",
    "EMAIL_RE = re.compile(r\"[\\w\\.-]+@[\\w\\.-]+\")\n",
    "UNIT_RE  = re.compile(r\"([가-힣A-Za-z·\\s\\-/()]{2,40}?(?:팀|센터|처|단|과|부|본부|위원회|연구소|지원실|실|연대|학부|학과))\")\n",
    "\n",
    "\n",
    "def last_seg(title: str):\n",
    "    return title.split(\"/\")[-1].strip() if isinstance(title, str) else \"\"\n",
    "\n",
    "\n",
    "def clean_name(s: str) -> str:\n",
    "    s = re.sub(r\"\\([^)]*\\)\", \"\", str(s))\n",
    "    s = re.sub(r\"[\\s\\-/·]+\", \"\", s)\n",
    "    return s.lower()\n",
    "\n",
    "\n",
    "def extract_units_and_contacts(row):\n",
    "    text = row[\"content\"] if isinstance(row[\"content\"], str) else \"\"\n",
    "    title = row[\"title\"]; url = row[\"url\"]; source = row[\"source\"]\n",
    "    out = []\n",
    "\n",
    "    for m in UNIT_RE.finditer(text):\n",
    "        unit = m.group(1).strip()\n",
    "        win = 140\n",
    "        start, end = max(0, m.start()-win), min(len(text), m.end()+win)\n",
    "        near = text[start:end]\n",
    "        phones = PHONE_RE.findall(near)\n",
    "        emails = EMAIL_RE.findall(near)\n",
    "        out.append({\n",
    "            \"unit\": unit,\n",
    "            \"phone\": phones[-1] if phones else \"없음\",\n",
    "            \"email\": emails[-1] if emails else \"없음\",\n",
    "            \"title\": title, \"url\": url, \"source\": source, \"how\": \"content\"\n",
    "        })\n",
    "\n",
    "\n",
    "    hint = last_seg(title)\n",
    "    mh = UNIT_RE.search(hint)\n",
    "    if mh:\n",
    "        phones = PHONE_RE.findall(text)\n",
    "        emails = EMAIL_RE.findall(text)\n",
    "        out.append({\n",
    "            \"unit\": mh.group(1).strip(),\n",
    "            \"phone\": phones[-1] if phones else \"없음\",\n",
    "            \"email\": emails[-1] if emails else \"없음\",\n",
    "            \"title\": title, \"url\": url, \"source\": source, \"how\": \"title\"\n",
    "        })\n",
    "\n",
    "\n",
    "    if not out:\n",
    "        phones = PHONE_RE.findall(text)\n",
    "        emails = EMAIL_RE.findall(text)\n",
    "        if phones or emails:\n",
    "            cand = hint if hint else \"미상\"\n",
    "            out.append({\n",
    "                \"unit\": cand,\n",
    "                \"phone\": phones[-1] if phones else \"없음\",\n",
    "                \"email\": emails[-1] if emails else \"없음\",\n",
    "                \"title\": title, \"url\": url, \"source\": source, \"how\": \"fallback\"\n",
    "            })\n",
    "    return out\n",
    "\n",
    "contact_cands = []\n",
    "for _, r in df.iterrows():\n",
    "    contact_cands.extend(extract_units_and_contacts(r))\n",
    "\n",
    "\n",
    "contacts_raw = pd.DataFrame(contact_cands)\n",
    "if contacts_raw.empty:\n",
    "    contacts_df = pd.DataFrame(columns=[\n",
    "        \"unit\",\"phone\",\"email\",\"title\",\"url\",\"source\",\"unit_norm\",\"cluster_id\",\n",
    "        \"unit_canonical\",\"search_text\"\n",
    "    ])\n",
    "else:\n",
    "    contacts_raw[\"unit_norm\"] = contacts_raw[\"unit\"].apply(clean_name)\n",
    "\n",
    "    cluster_map = {}; reps = []\n",
    "    for name in contacts_raw[\"unit_norm\"].unique():\n",
    "        assigned = False\n",
    "        for cid, rep in enumerate(reps):\n",
    "            if SequenceMatcher(None, name, rep).ratio() >= 0.92:\n",
    "                cluster_map[name] = cid; assigned = True; break\n",
    "        if not assigned:\n",
    "            cid = len(reps); reps.append(name); cluster_map[name] = cid\n",
    "\n",
    "    contacts_raw[\"cluster_id\"] = contacts_raw[\"unit_norm\"].map(cluster_map.get)\n",
    "\n",
    "    rep_map = {}\n",
    "    for cid in set(cluster_map.values()):\n",
    "        members = contacts_raw[contacts_raw[\"cluster_id\"] == cid]\n",
    "        rep_map[cid] = members[\"unit\"].value_counts().idxmax()\n",
    "    contacts_raw[\"unit_canonical\"] = contacts_raw[\"cluster_id\"].map(rep_map.get)\n",
    "\n",
    "    contacts_df = (contacts_raw\n",
    "                .sort_values([\"cluster_id\",\"url\"])\n",
    "                .drop_duplicates(subset=[\"cluster_id\",\"phone\",\"email\"])\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "    contacts_df[\"search_text\"] = (\n",
    "        contacts_df[\"unit_canonical\"].fillna(\"\") + \" \" +\n",
    "        contacts_df[\"unit\"].fillna(\"\") + \" \" +\n",
    "        contacts_df[\"title\"].fillna(\"\")\n",
    "    ).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "\n",
    "if not contacts_df.empty:\n",
    "    bm25_contacts = BM25Okapi([tokenize_kor(t) for t in contacts_df[\"search_text\"].tolist()])\n",
    "    emb_contacts = model.encode([f\"passage: {t}\" for t in contacts_df[\"search_text\"].tolist()],\n",
    "                                normalize_embeddings=True, show_progress_bar=False).astype(np.float32)\n",
    "\n",
    "    cluster_df = contacts_df.groupby(\"cluster_id\").agg({\n",
    "        \"unit_canonical\": \"first\",\n",
    "        \"search_text\": \"first\"\n",
    "    }).reset_index()\n",
    "    cluster_df[\"rep_norm\"] = cluster_df[\"unit_canonical\"].apply(lambda s: re.sub(r\"[\\s\\-/·]+\",\"\", str(s)).lower())\n",
    "\n",
    "    cluster_rep_emb = model.encode(\n",
    "        [f\"passage: {t}\" for t in cluster_df[\"search_text\"].tolist()],\n",
    "        normalize_embeddings=True, show_progress_bar=False\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    cluster_members = contacts_df.groupby(\"cluster_id\").indices\n",
    "\n",
    "else:\n",
    "    bm25_contacts, emb_contacts = None, None\n",
    "    cluster_df = pd.DataFrame(columns=[\"cluster_id\",\"unit_canonical\",\"search_text\",\"rep_norm\"])\n",
    "    cluster_rep_emb = np.zeros((0, 768), dtype=np.float32)\n",
    "    cluster_members = {}\n",
    "\n",
    "\n",
    "NOTICE_KEYWORDS = [\"공지\",\"안내\",\"모집\",\"변경\",\"연장\",\"일정\",\"신청\",\"발표\",\"채용\",\"장학\",\"기간\",\"마감\",\"등록\",\"수강\",\"정정\"]\n",
    "\n",
    "\n",
    "def _minmax(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    lo, hi = np.nanmin(x), np.nanmax(x)\n",
    "    if hi - lo < 1e-9:\n",
    "        return np.zeros_like(x)\n",
    "    return (x - lo) / (hi - lo + 1e-9)\n",
    "\n",
    "\n",
    "def recency_score(ts, now=KST_NOW, half_life_days=30):\n",
    "    if pd.isna(ts) or ts is None:\n",
    "        return 0.0\n",
    "    days = max((now - ts).days, 0)\n",
    "    return float(np.exp(-np.log(2) * days / half_life_days))\n",
    "\n",
    "\n",
    "def hybrid_search_docs(query, top_k=10, alpha=0.6, half_life_days=30, recency_weight=0.45, notice_boost=0.20):\n",
    "    qv = embed_query(query)\n",
    "    dense_raw = embeddings @ qv\n",
    "    bm25_raw  = bm25.get_scores(tokenize_kor(query))\n",
    "\n",
    "    dense = _minmax(dense_raw); bm25s = _minmax(bm25_raw)\n",
    "    base = alpha * dense + (1 - alpha) * bm25s\n",
    "\n",
    "    rec = np.asarray([recency_score(ts, half_life_days=half_life_days) for ts in chunk_df[\"updated_at\"]])\n",
    "    rec = _minmax(rec)\n",
    "    bonus = recency_weight * rec\n",
    "\n",
    "    is_notice_q = any(k in query for k in NOTICE_KEYWORDS)\n",
    "    if is_notice_q:\n",
    "        bonus = bonus + notice_boost * chunk_df[\"notice_flag\"].to_numpy()\n",
    "\n",
    "    scores = base + bonus\n",
    "\n",
    "    tmp = chunk_df.copy()\n",
    "    tmp[\"score\"] = scores\n",
    "    best_idx = tmp.groupby(\"url\")[\"score\"].idxmax()\n",
    "    doc_top = tmp.loc[best_idx].copy()\n",
    "    doc_top.sort_values(by=[\"score\",\"updated_at\"], ascending=[False, False], inplace=True, na_position=\"last\")\n",
    "    return doc_top.head(top_k)[[\"title\",\"url\",\"score\",\"updated_at\",\"notice_flag\",\"text\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "CONTACT_KWS = [\"연락처\",\"전화\",\"전화번호\",\"이메일\",\"메일\",\"담당자\",\"상담\",\"교직원\",\"직원검색\",\"문의\",\"contact\",\"email\",\"phone\"]\n",
    "\n",
    "\n",
    "def is_contact_query(q: str) -> bool:\n",
    "    return any(k in q for k in CONTACT_KWS)\n",
    "\n",
    "\n",
    "def match_units_for_query(query, topn=10):\n",
    "    if contacts_df.empty or cluster_df.empty:\n",
    "        return []\n",
    "    q_clean = re.sub(r\"[\\s\\-/·]+\",\"\", str(query)).lower()\n",
    "\n",
    "    sim_str = cluster_df[\"rep_norm\"].apply(lambda x: SequenceMatcher(None, q_clean, x).ratio()).to_numpy()\n",
    "\n",
    "    qv = embed_query(query)\n",
    "    sim_emb = cluster_rep_emb @ qv\n",
    "\n",
    "\n",
    "    def _mm_vec(v):\n",
    "        lo, hi = float(np.min(v)), float(np.max(v))\n",
    "        return np.zeros_like(v, dtype=np.float32) if hi - lo < 1e-9 else (v - lo) / (hi - lo + 1e-9)\n",
    "    \n",
    "    hybrid = 0.5*_mm_vec(sim_str.astype(np.float32)) + 0.5*_mm_vec(sim_emb.astype(np.float32))\n",
    "    order = np.argsort(-hybrid)[:topn]\n",
    "\n",
    "    return cluster_df.loc[order, \"cluster_id\"].tolist()\n",
    "\n",
    "\n",
    "def hybrid_search_contacts(query, top_k=5, alpha=0.6):\n",
    "    if contacts_df.empty:\n",
    "        return pd.DataFrame(columns=[\"unit_canonical\",\"phone\",\"email\",\"title\",\"url\",\"score\"])\n",
    "\n",
    "    cand_clusters = match_units_for_query(query, topn=20)\n",
    "\n",
    "    if cand_clusters:\n",
    "        cand_idx = sorted({i for cid in cand_clusters for i in cluster_members.get(cid, [])})\n",
    "    else:\n",
    "        cand_idx = list(range(len(contacts_df)))\n",
    "\n",
    "    q_tokens = tokenize_kor(query)\n",
    "    qv = embed_query(query)\n",
    "\n",
    "    dense_all = emb_contacts @ qv\n",
    "    bm25_all  = bm25_contacts.get_scores(q_tokens)\n",
    "\n",
    "    dense = dense_all[cand_idx]\n",
    "    bm25s = bm25_all[cand_idx]\n",
    "\n",
    "\n",
    "    def _mm(x):\n",
    "        lo, hi = float(np.min(x)), float(np.max(x))\n",
    "        return np.zeros_like(x, dtype=np.float32) if hi - lo < 1e-9 else (x - lo) / (hi - lo + 1e-9)\n",
    "    base = alpha * _mm(dense.astype(np.float32)) + (1 - alpha) * _mm(bm25s.astype(np.float32))\n",
    "    sub = contacts_df.iloc[cand_idx].copy()\n",
    "    title_hint = sub[\"title\"].str.contains(r\"(교직원|직원검색|연락처|전화)\", regex=True, na=False).astype(int).to_numpy()\n",
    "    is_board   = sub[\"url\"].str.contains(r\"/bbs/\").fillna(False).astype(int).to_numpy()\n",
    "    q_norm     = re.sub(r\"[\\s\\-/·]+\",\"\", query.lower())\n",
    "    contains   = sub[\"unit\"].apply(lambda d: int(re.sub(r\"[\\s\\-/·]+\",\"\", str(d)).lower() in q_norm or q_norm in re.sub(r\"[\\s\\-/·]+\",\"\", str(d)).lower())).to_numpy()\n",
    "\n",
    "    scores = base + 0.15*title_hint - 0.20*is_board + 0.25*contains\n",
    "\n",
    "    sub[\"score\"] = scores\n",
    "    sub.sort_values(\"score\", ascending=False, inplace=True)\n",
    "\n",
    "    return sub.head(top_k)[[\"unit_canonical\",\"phone\",\"email\",\"title\",\"url\",\"score\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def search(query, top_k=8):\n",
    "    if is_contact_query(query):\n",
    "        cands = hybrid_search_contacts(query, top_k=max(5, top_k//2))\n",
    "        if not cands.empty and ((cands[\"phone\"]!=\"없음\") | (cands[\"email\"]!=\"없음\")).any():\n",
    "            return {\"type\":\"contact\", \"results\": cands.to_dict(orient=\"records\")}\n",
    "        docs = hybrid_search_docs(query, top_k=top_k)\n",
    "        return {\"type\":\"docs\", \"results\": docs.to_dict(orient=\"records\")}\n",
    "    else:\n",
    "        docs = hybrid_search_docs(query, top_k=top_k)\n",
    "        return {\"type\":\"docs\", \"results\": docs.to_dict(orient=\"records\")}\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(\"../model/artifacts\", exist_ok=True)\n",
    "np.save(\"../model/artifacts/embeddings.npy\", embeddings)\n",
    "chunk_df.to_parquet(\"../model/artifacts/chunk_df.parquet\", index=False)\n",
    "if 'contacts_df' in locals() and not contacts_df.empty:\n",
    "    contacts_df.to_csv(\"../model/artifacts/contacts.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/q0b7nlrj7vgc1sv7yjw0n2xm0000gn/T/ipykernel_31794/830844548.py:413: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  title_hint = sub[\"title\"].str.contains(r\"(교직원|직원검색|연락처|전화)\", regex=True, na=False).astype(int).to_numpy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_canonical</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>컴퓨터소프트웨어공학과</td>\n",
       "      <td>02-2610-1988</td>\n",
       "      <td>없음</td>\n",
       "      <td>학사안내/현장실습</td>\n",
       "      <td>https://www.dongyang.ac.kr/dmu/4756/subview.do</td>\n",
       "      <td>1.208546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>컴퓨터소프트웨어공학과</td>\n",
       "      <td>02-2610-1843</td>\n",
       "      <td>min101933@dongyan</td>\n",
       "      <td>학부ㆍ학과/컴퓨터소프트웨어공학과</td>\n",
       "      <td>https://www.dongyang.ac.kr/dmu/4573/subview.do</td>\n",
       "      <td>1.133818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>컴퓨터소프트웨어공학과</td>\n",
       "      <td>02-2610-1843</td>\n",
       "      <td>min101933@dongyang.ac.kr</td>\n",
       "      <td>학부ㆍ학과/컴퓨터소프트웨어공학과</td>\n",
       "      <td>https://www.dongyang.ac.kr/dmu/4573/subview.do</td>\n",
       "      <td>1.133818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>컴퓨터소프트웨어공학과</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>대학소개/대학기구</td>\n",
       "      <td>https://www.dongyang.ac.kr/dmu/4361/subview.do</td>\n",
       "      <td>1.035099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>학년도 컴퓨터소프트웨어공학과</td>\n",
       "      <td>없음</td>\n",
       "      <td>없음</td>\n",
       "      <td>[컴소] 2023학년도 컴퓨터소프트웨어공학과 대학교육과정 SQF 인정</td>\n",
       "      <td>https://www.dongyang.ac.kr/combBbs/dmu/84/320/...</td>\n",
       "      <td>0.848281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unit_canonical         phone                     email  \\\n",
       "0      컴퓨터소프트웨어공학과  02-2610-1988                        없음   \n",
       "1      컴퓨터소프트웨어공학과  02-2610-1843         min101933@dongyan   \n",
       "2      컴퓨터소프트웨어공학과  02-2610-1843  min101933@dongyang.ac.kr   \n",
       "3      컴퓨터소프트웨어공학과            없음                        없음   \n",
       "4  학년도 컴퓨터소프트웨어공학과            없음                        없음   \n",
       "\n",
       "                                    title  \\\n",
       "0                               학사안내/현장실습   \n",
       "1                       학부ㆍ학과/컴퓨터소프트웨어공학과   \n",
       "2                       학부ㆍ학과/컴퓨터소프트웨어공학과   \n",
       "3                               대학소개/대학기구   \n",
       "4  [컴소] 2023학년도 컴퓨터소프트웨어공학과 대학교육과정 SQF 인정   \n",
       "\n",
       "                                                 url     score  \n",
       "0     https://www.dongyang.ac.kr/dmu/4756/subview.do  1.208546  \n",
       "1     https://www.dongyang.ac.kr/dmu/4573/subview.do  1.133818  \n",
       "2     https://www.dongyang.ac.kr/dmu/4573/subview.do  1.133818  \n",
       "3     https://www.dongyang.ac.kr/dmu/4361/subview.do  1.035099  \n",
       "4  https://www.dongyang.ac.kr/combBbs/dmu/84/320/...  0.848281  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search_contacts(\"학생상담센터 이메일\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469db5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'docs',\n",
       " 'results': [{'title': '[컴소] 2025학년도 1학기 컴퓨터소프트웨어공학과 기말고사 시간표 안내',\n",
       "   'url': 'https://www.dongyang.ac.kr/combBbs/dmu/84/320/249060/view.do?layout=unknown',\n",
       "   'score': 1.1944537606676444,\n",
       "   'updated_at': Timestamp('2025-06-10 00:00:00+0900', tz='UTC+09:00'),\n",
       "   'notice_flag': 1,\n",
       "   'text': '[컴소] 2025학년도 1학기 컴퓨터소프트웨어공학과 기말고사 시간표 안내 부서: 학과공지 작성자: 민** 작성일: 2025.06.10'},\n",
       "  {'title': '[컴소] 2023-1 컴퓨터소프트웨어공학과 강의시간표 및 수강신청 안내(03/09)',\n",
       "   'url': 'https://www.dongyang.ac.kr/combBbs/dmu/84/320/121464/view.do?layout=unknown',\n",
       "   'score': 0.9781315294119632,\n",
       "   'updated_at': Timestamp('2023-02-01 00:00:00+0900', tz='UTC+09:00'),\n",
       "   'notice_flag': 1,\n",
       "   'text': '[컴소] 2023-1 컴퓨터소프트웨어공학과 강의시간표 및 수강신청 안내(03/09) 부서: 학과공지 작성자: 오** 작성일: 2023.02.01'},\n",
       "  {'title': '[컴소] 2025-1학기 컴퓨터소프트웨어공학과 강의시간표 및 수강신청 안내(02/28 수정)',\n",
       "   'url': 'https://www.dongyang.ac.kr/combBbs/dmu/84/320/130183/view.do?layout=unknown',\n",
       "   'score': 0.9739198661061367,\n",
       "   'updated_at': Timestamp('2025-02-05 00:00:00+0900', tz='UTC+09:00'),\n",
       "   'notice_flag': 1,\n",
       "   'text': '[컴소] 2025-1학기 컴퓨터소프트웨어공학과 강의시간표 및 수강신청 안내(02/28 수정) 부서: 학과공지 작성자: 민** 작성일: 2025.02.05'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"컴소과 시간표\", top_k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
