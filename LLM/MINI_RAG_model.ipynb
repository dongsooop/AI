{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72895453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "with open(\"../data/school_info/dmu_documents_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_json = pd.DataFrame(data)\n",
    "df_json = df_json.dropna(subset=[\"content\"])\n",
    "df_json[\"source\"] = \"main\"\n",
    "\n",
    "dept_dir = \"../data/dept\"\n",
    "dept_files = [f for f in os.listdir(dept_dir) if f.endswith(\"_notices.csv\")]\n",
    "\n",
    "df_list = []\n",
    "for file in dept_files:\n",
    "    file_path = os.path.join(dept_dir, file)\n",
    "    try:\n",
    "        df_dept = pd.read_csv(file_path)\n",
    "        df_dept[\"title\"] = df_dept[\"ì œëª©\"].fillna(\"\")\n",
    "        df_dept[\"url\"] = df_dept[\"ë§í¬\"].fillna(\"\")\n",
    "\n",
    "        df_dept[\"content\"] = (\n",
    "            \"ë¶€ì„œ: \" + df_dept[\"ë¶€ì„œ\"].fillna(\"ì—†ìŒ\") + \"\\n\"\n",
    "            + \"ì‘ì„±ì: \" + df_dept[\"ì‘ì„±ì\"].fillna(\"ì—†ìŒ\") + \"\\n\"\n",
    "            + \"ì‘ì„±ì¼: \" + df_dept[\"ì‘ì„±ì¼\"].astype(str).fillna(\"ì—†ìŒ\")\n",
    "        )\n",
    "        df_dept[\"source\"] = file.replace(\"_notices.csv\", \"\")\n",
    "        df_list.append(df_dept[[\"title\", \"content\", \"url\", \"source\"]])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ íŒŒì¼ ì˜¤ë¥˜: {file_path} - {e}\")\n",
    "\n",
    "df_csv = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame(columns=[\"title\", \"content\", \"url\", \"source\"])\n",
    "\n",
    "df = pd.concat([df_json, df_csv], ignore_index=True)\n",
    "df = df.dropna(subset=[\"title\", \"content\"])\n",
    "df[\"combined_text\"] = df[\"title\"] + \" \" + df[\"content\"]\n",
    "df[\"fulltext\"] = df[\"combined_text\"].apply(lambda x: re.sub(r\"\\s+\", \" \", x.strip()))\n",
    "\n",
    "tokenized_corpus = [doc.split() for doc in df[\"fulltext\"]]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "embeddings = model.encode(df[\"fulltext\"].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac0e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contact_info(text):\n",
    "    phone_lines = []\n",
    "    email_lines = []\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        if 'íŒ©ìŠ¤' in line or 'fax' in line.lower():\n",
    "            continue\n",
    "        if re.search(r'\\b0\\d{1,2}[-\\s]?\\d{3,4}[-\\s]?\\d{4}\\b', line):\n",
    "            phone_lines.append(line)\n",
    "        if re.search(r'[\\w\\.-]+@[\\w\\.-]+', line):\n",
    "            email_lines.append(line)\n",
    "\n",
    "    for line in phone_lines:\n",
    "        if any(email in line for email in email_lines):\n",
    "            phones = re.findall(r'\\b0\\d{1,2}[-\\s]?\\d{3,4}[-\\s]?\\d{4}\\b', line)\n",
    "            emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', line)\n",
    "            if phones and emails:\n",
    "                return {'ì „í™”ë²ˆí˜¸': phones[0], 'ì´ë©”ì¼': emails[0]}\n",
    "\n",
    "    emails = []\n",
    "    phones = []\n",
    "    for line in text.splitlines():\n",
    "        line_phones = re.findall(r'\\b0\\d{1,2}[-\\s]?\\d{3,4}[-\\s]?\\d{4}\\b', line)\n",
    "        line_emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', line)\n",
    "        if line_emails:\n",
    "            emails.extend(line_emails)\n",
    "        if line_phones:\n",
    "            phones.extend(line_phones)\n",
    "\n",
    "    return {\n",
    "        'ì „í™”ë²ˆí˜¸': phones[-1] if phones else 'ì—†ìŒ',\n",
    "        'ì´ë©”ì¼': emails[-1] if emails else 'ì—†ìŒ'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896e0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query, top_k=10, alpha=0.99, threshold=0.75):\n",
    "    q_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    cosine_scores = cosine_similarity(q_embedding.cpu().numpy(), embeddings.cpu().numpy())[0]\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    penalty = df[\"source\"].notnull().astype(float) * 0.15\n",
    "    hybrid_scores = alpha * cosine_scores + (1 - alpha) * bm25_scores - penalty\n",
    "\n",
    "    candidates = [\n",
    "        (i, hybrid_scores[i]) for i in range(len(hybrid_scores)) if hybrid_scores[i] >= threshold\n",
    "    ]\n",
    "    sorted_candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    top_idx = [idx for idx, _ in sorted_candidates]\n",
    "    results = df.iloc[top_idx][[\"title\", \"url\", \"fulltext\"]].copy()\n",
    "    results[\"score\"] = [s for _, s in sorted_candidates]\n",
    "    return results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "210b6f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ì œëª©: 2017-1í•™ê¸° ì»´í“¨í„°ê³µí•™ë¶€ ì‚¬ë¬¼í•¨ ë°°ë¶€ ê³µì§€\n",
      "ğŸ”— URL: https://www.dongyang.ac.kr/combBbs/dmu/86/321/71558/view.do\n",
      "ğŸ“ˆ ì ìˆ˜: 0.5609\n",
      "ğŸ“ ì „í™”ë²ˆí˜¸: ì—†ìŒ, ğŸ“§ ì´ë©”ì¼: ì—†ìŒ\n",
      "--------------------------------------------------\n",
      "ğŸ“Œ ì œëª©: (í†µì‹ ) ì •ë³´í†µì‹ ê³µí•™ê³¼ PCBì„¤ê³„ J2 ê°•ì¢Œ íœ´ë³´ê°• ì¼ì • ê³µì§€\n",
      "ğŸ”— URL: https://www.dongyang.ac.kr/combBbs/dmu/90/314/248950/view.do\n",
      "ğŸ“ˆ ì ìˆ˜: 0.5517\n",
      "ğŸ“ ì „í™”ë²ˆí˜¸: ì—†ìŒ, ğŸ“§ ì´ë©”ì¼: ì—†ìŒ\n",
      "--------------------------------------------------\n",
      "ğŸ“Œ ì œëª©: ìˆ˜ì—… ì‹œê°„í‘œ ê³µì§€\n",
      "ğŸ”— URL: https://www.dongyang.ac.kr/combBbs/dmu/98/309/70470/view.do\n",
      "ğŸ“ˆ ì ìˆ˜: 0.5478\n",
      "ğŸ“ ì „í™”ë²ˆí˜¸: ì—†ìŒ, ğŸ“§ ì´ë©”ì¼: ì—†ìŒ\n",
      "--------------------------------------------------\n",
      "ğŸ“Œ ì œëª©: ë°˜ë„ì²´ì „ìê³µí•™ê³¼ í”„ë¡œê·¸ë˜ë°ì–¸ì–´ H2 ê°•ì¢Œ íœ´ë³´ê°• ì¼ì • ê³µì§€\n",
      "ğŸ”— URL: https://www.dongyang.ac.kr/combBbs/dmu/92/315/248777/view.do\n",
      "ğŸ“ˆ ì ìˆ˜: 0.5465\n",
      "ğŸ“ ì „í™”ë²ˆí˜¸: ì—†ìŒ, ğŸ“§ ì´ë©”ì¼: ì—†ìŒ\n",
      "--------------------------------------------------\n",
      "ğŸ“Œ ì œëª©: [ì»´ì •] 2022-1 ì»´í“¨í„°ì •ë³´ê³µí•™ê³¼ ê°•ì˜ì‹œê°„í‘œ ë° ìˆ˜ê°•ì‹ ì²­ ì•ˆë‚´(03/10)\n",
      "ğŸ”— URL: https://www.dongyang.ac.kr/combBbs/dmu/86/321/118519/view.do\n",
      "ğŸ“ˆ ì ìˆ˜: 0.5437\n",
      "ğŸ“ ì „í™”ë²ˆí˜¸: ì—†ìŒ, ğŸ“§ ì´ë©”ì¼: ì—†ìŒ\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"ì»´ê³µ í•™ê³¼ ê³µì§€\"\n",
    "results = hybrid_search(query, top_k=5, threshold=0.4)\n",
    "\n",
    "for i, row in results.iterrows():\n",
    "    print(f\"ğŸ“Œ ì œëª©: {row['title']}\")\n",
    "    print(f\"ğŸ”— URL: {row['url']}\")\n",
    "    print(f\"ğŸ“ˆ ì ìˆ˜: {row['score']:.4f}\")\n",
    "    contact = extract_contact_info(row[\"fulltext\"])\n",
    "    print(f\"ğŸ“ ì „í™”ë²ˆí˜¸: {contact['ì „í™”ë²ˆí˜¸']}, ğŸ“§ ì´ë©”ì¼: {contact['ì´ë©”ì¼']}\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
